CÆ¡ cháº¿ Background Agents - Giáº£i thÃ­ch chi tiáº¿t ğŸ”¬

  TÃ´i sáº½ giáº£i thÃ­ch chi tiáº¿t cÆ¡ cháº¿ nÃ y hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o, tá»« kiáº¿n trÃºc Ä‘áº¿n implementation.

  ---
  ğŸ—ï¸ Kiáº¿n trÃºc tá»•ng quan

  Traditional Sequential Model (CÃ¡ch cÅ©)

  User Request
      â†“
  [Main Agent] â”€â”€â†’ Task 1 (5 min) â”€â”€â†’ Done
      â†“
  [Main Agent] â”€â”€â†’ Task 2 (10 min) â”€â”€â†’ Done
      â†“
  [Main Agent] â”€â”€â†’ Task 3 (8 min) â”€â”€â†’ Done
      â†“
  Total Time: 23 minutes
  CPU Idle: 66% (chá» Ä‘á»£i API responses)

  Oh My OpenCode Parallel Model (CÃ¡ch má»›i)

  User Request
      â†“
  [OmO Orchestrator]
      â”œâ”€â”€â†’ [Agent 1: Background] â”€â”€â†’ Task 1 (5 min)
      â”œâ”€â”€â†’ [Agent 2: Background] â”€â”€â†’ Task 2 (10 min)
      â””â”€â”€â†’ [Agent 3: Main Thread] â”€â”€â†’ Task 3 (8 min)
           â†“
      [Wait for all] â”€â”€â†’ Sync results
           â†“
      [Integration] â”€â”€â†’ Ship
           â†“
  Total Time: 10 minutes (longest task)
  Efficiency: 2.3x faster

  ---
  ğŸ” Chi tiáº¿t tá»«ng component

  1. OmO Orchestrator - Bá»™ nÃ£o Ä‘iá»u phá»‘i

âº Read(README.md)
  â¿  Read 20 lines

âº OmO Agent characteristics:
  Model: Claude Opus 4.5
  Role: Orchestrator + Main executor
  Capabilities:
    - Extended thinking (32k token budget)
    - Task delegation intelligence
    - Parallel execution coordination
    - Todo-driven workflow
    - Background task monitoring

  Nhiá»‡m vá»¥ cá»§a OmO:
  1. PhÃ¢n tÃ­ch request - Hiá»ƒu yÃªu cáº§u phá»©c táº¡p
  2. Task decomposition - Chia thÃ nh subtasks
  3. Agent selection - Chá»n specialist phÃ¹ há»£p
  4. Execution strategy - Quyáº¿t Ä‘á»‹nh parallel vs sequential
  5. Monitor & integrate - Theo dÃµi vÃ  tá»•ng há»£p káº¿t quáº£

  ---
  2. Background Task System - CÆ¡ cháº¿ cháº¡y ngáº§m

âº Read(README.md)
  â¿  Read 15 lines

âº CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:

  // Pseudo-code minh há»a
  class BackgroundTaskManager {
    // Pool chá»©a cÃ¡c background tasks
    private tasks: Map<string, BackgroundTask> = new Map();

    // Spawn background agent
    spawnBackground(agent: Agent, task: Task): TaskHandle {
      const handle = {
        id: generateId(),
        agent: agent,
        task: task,
        status: 'running',
        startTime: Date.now()
      };

      // Execute asynchronously
      this.executeAsync(handle);

      // Return handle immediately (non-blocking)
      return handle;
    }

    // Execute khÃ´ng block main thread
    async executeAsync(handle: TaskHandle) {
      try {
        // Agent cháº¡y Ä‘á»™c láº­p
        const result = await handle.agent.execute(handle.task);

        // LÆ°u káº¿t quáº£
        handle.status = 'completed';
        handle.result = result;

        // Notify orchestrator
        this.notifyCompletion(handle);
      } catch (error) {
        handle.status = 'failed';
        handle.error = error;
        this.notifyError(handle);
      }
    }

    // Wait for specific tasks
    async waitFor(handles: TaskHandle[]): Promise<Results> {
      return Promise.all(
        handles.map(h => this.getResult(h))
      );
    }
  }

  ---
  3. Workflow Example - Full-Stack App

  HÃ£y xem má»™t vÃ­ dá»¥ cá»¥ thá»ƒ:

  User: "Build a todo app with React frontend and Node.js backend"

  Phase 1: OmO Analysis (10 seconds)

  OmO thinking:
  "TÃ´i cáº§n:
  1. Design database schema
  2. Build REST API (backend)
  3. Create React components (frontend)
  4. Integration

  Dependencies:
  - Frontend cáº§n API contract, nhÆ°ng cÃ³ thá»ƒ lÃ m song song náº¿u define contract trÆ°á»›c
  - Database schema pháº£i xong trÆ°á»›c khi code API

  Strategy:
  - Define API contract first (sequential, 30s)
  - Parallel: API implementation + Frontend development
  - Integration (sequential, 5min)
  "

  Phase 2: Contract Definition (30 seconds)

  OmO executes:
  [Main Thread] Define API Contract
  â”œâ”€ POST /todos
  â”œâ”€ GET /todos
  â”œâ”€ PUT /todos/:id
  â”œâ”€ DELETE /todos/:id
  â””â”€ Schema: { id, title, completed, createdAt }

  Output: openapi.yaml

  Phase 3: Parallel Execution (15 minutes)

  // OmO spawns 2 background tasks

  [Task 1: Background] @frontend-ui-ux-engineer
  â”œâ”€ Prompt: "Build React todo app using this API contract"
  â”œâ”€ Model: Gemini 3 Pro (creative, beautiful UI)
  â”œâ”€ Context: openapi.yaml
  â”œâ”€ Output: src/components/*, src/App.tsx
  â””â”€ Status: Running in background...

  [Task 2: Main Thread] @OmO
  â”œâ”€ Task: "Implement Node.js API following contract"
  â”œâ”€ Model: Claude Opus 4.5 (logical, reliable)
  â”œâ”€ Steps:
  â”‚   1. Setup Express server
  â”‚   2. Create database models
  â”‚   3. Implement CRUD endpoints
  â”‚   4. Add validation middleware
  â”‚   5. Write tests
  â””â”€ Status: Executing on main thread...

  // Timeline:
  T+0:  Both start
  T+8:  Backend 60% done, Frontend 50% done
  T+12: Backend done, Frontend 80% done
  T+15: Both completed

  Notification system:
  // Background task completion
  [T+15min] Background Notification:
  "âœ… @frontend-ui-ux-engineer completed:
   - TodoList component
   - TodoItem component
   - AddTodo form
   - Beautiful Tailwind styling
   - Responsive design
   Ready for integration!"

  OmO receives notification and proceeds...

  Phase 4: Integration (5 minutes)

  [Main Thread] OmO integrates:
  â”œâ”€ Review backend code: âœ… All endpoints working
  â”œâ”€ Review frontend code: âœ… UI looks gorgeous
  â”œâ”€ Connect frontend to backend:
  â”‚   â””â”€ Update API_URL in config
  â”œâ”€ Test integration:
  â”‚   â”œâ”€ Create todo: âœ…
  â”‚   â”œâ”€ List todos: âœ…
  â”‚   â”œâ”€ Update todo: âœ…
  â”‚   â””â”€ Delete todo: âœ…
  â””â”€ Final verification: âœ… All working!

  Total Time Comparison:

  Sequential approach:
  â”œâ”€ API Contract: 30s
  â”œâ”€ Backend: 15min
  â”œâ”€ Frontend: 15min
  â””â”€ Integration: 5min
  Total: 35.5 minutes

  Parallel approach (Oh My OpenCode):
  â”œâ”€ API Contract: 30s
  â”œâ”€ Backend + Frontend: 15min (parallel!)
  â””â”€ Integration: 5min
  Total: 20.5 minutes

  Time saved: 42% faster!

  ---
  ğŸ”§ Technical Implementation Details

  1. Inter-Agent Communication

  // Orchestrator â†’ Background Agent
  interface TaskMessage {
    type: 'delegate';
    agent: 'frontend-ui-ux-engineer';
    task: {
      description: 'Build React todo app';
      context: {
        apiContract: 'openapi.yaml',
        requirements: ['responsive', 'beautiful UI']
      };
      expectedOutput: ['src/components/*'];
    };
    mode: 'background'; // hoáº·c 'blocking'
  }

  // Background Agent â†’ Orchestrator
  interface CompletionMessage {
    type: 'completed';
    taskId: 'task-123';
    result: {
      files: ['src/App.tsx', 'src/components/TodoList.tsx'],
      summary: 'Built React app with Tailwind styling',
      notes: 'Used shadcn/ui for better UX'
    };
    duration: 900000; // 15 minutes in ms
  }

  2. Context Sharing Mechanism

  // Shared context giá»¯a agents
  class SharedContext {
    // Main context (read by all)
    readonly projectContext: {
      structure: ProjectStructure;
      dependencies: Dependencies;
      conventions: CodingStandards;
    };

    // Agent-specific outputs
    private outputs: Map<AgentId, AgentOutput> = new Map();

    // Agent Ä‘á»c outputs cá»§a agent khÃ¡c
    getOutput(agentId: AgentId): AgentOutput {
      return this.outputs.get(agentId);
    }

    // Agent ghi output cá»§a mÃ¬nh
    setOutput(agentId: AgentId, output: AgentOutput) {
      this.outputs.set(agentId, output);
      this.notifyDependents(agentId);
    }
  }

  Example:
  // Backend agent hoÃ n thÃ nh
  sharedContext.setOutput('backend-agent', {
    apiContract: openApiSpec,
    endpoints: [...],
    models: [...]
  });

  // Frontend agent tá»± Ä‘á»™ng access
  const backendOutput = sharedContext.getOutput('backend-agent');
  const apiSpec = backendOutput.apiContract;
  // Use apiSpec Ä‘á»ƒ generate API calls

  3. Dependency Management

  class TaskGraph {
    // Define dependencies
    private dependencies: Map<TaskId, TaskId[]> = new Map();

    // Build execution plan
    buildExecutionPlan(tasks: Task[]): ExecutionPlan {
      const plan: ExecutionPlan = {
        sequential: [],
        parallel: []
      };

      // Topological sort
      const sorted = this.topologicalSort(tasks);

      for (const task of sorted) {
        const deps = this.dependencies.get(task.id);

        if (deps.length === 0) {
          // No dependencies â†’ Can run in parallel
          plan.parallel.push(task);
        } else {
          // Has dependencies â†’ Must run after deps complete
          plan.sequential.push(task);
        }
      }

      return plan;
    }
  }

  Example dependency graph:
  User Request: "Build full-stack app"
      â†“
  [Define API Contract] (sequential, must go first)
      â†“
      â”œâ”€â”€â†’ [Build Backend] (parallel group 1)
      â””â”€â”€â†’ [Build Frontend] (parallel group 1)
           â†“
      [Integration] (sequential, wait for group 1)
           â†“
      [Testing] (sequential, final step)

  ---
  ğŸ¯ Advanced Scenarios

  Scenario 1: Massive Parallel Search

  User: "Find all implementations of authentication in our codebase and similar open-source projects"

  OmO execution plan:
  â”œâ”€ [Background] @explore
  â”‚   â””â”€ Task: "Search local codebase for auth patterns"
  â”‚       Tools: AST-grep, LSP
  â”‚       Time: 2 minutes
  â”‚
  â”œâ”€ [Background] @librarian
  â”‚   â””â”€ Task: "Search GitHub for auth implementations"
  â”‚       Tools: grep.app MCP
  â”‚       Time: 3 minutes
  â”‚
  â””â”€ [Main] @OmO
      â””â”€ Task: "Analyze auth requirements while searches run"
          Time: 2 minutes

  // All finish, aggregate results
  Aggregation (1 minute):
  â”œâ”€ Local: 15 auth implementations found
  â”œâ”€ GitHub: 50 examples from popular repos
  â””â”€ Combined analysis: Best practices + recommendations

  Total: 4 minutes (vs 6 minutes sequential)

  Scenario 2: Multi-Approach Debugging

  User: "Why is login failing intermittently?"

  OmO spawns multiple agents with different approaches:

  â”œâ”€ [Background] @explore (Fast pattern search)
  â”‚   â””â”€ "Search for auth-related errors in logs"
  â”‚       Time: 1 minute
  â”‚
  â”œâ”€ [Background] @librarian (Research known issues)
  â”‚   â””â”€ "Check GitHub issues + Stack Overflow"
  â”‚       Time: 2 minutes
  â”‚
  â””â”€ [Background] @oracle (Deep logical analysis)
      â””â”€ "Analyze auth flow logic for race conditions"
          Time: 5 minutes

  // Aggregation
  OmO synthesizes:
  â”œâ”€ @explore found: Timeout errors in logs
  â”œâ”€ @librarian found: Similar issue in JWT library v2.3
  â”œâ”€ @oracle found: Race condition in session store
  â””â”€ Root cause: Session store not thread-safe + old JWT lib

  Confidence: HIGH (3 agents agree on root cause)
  Time: 5 minutes (vs 8+ minutes trying approaches sequentially)

  Scenario 3: Incremental Delivery

  User: "Refactor entire auth system to use JWT"

  // Traditional: Wait until everything done
  Sequential:
  â”œâ”€ Research (10min)
  â”œâ”€ Plan (15min)
  â”œâ”€ Implement (60min)
  â””â”€ Test (20min)
  Total: 105 minutes, user waits 105 min for any output

  // Oh My OpenCode: Incremental delivery
  Parallel:
  â”œâ”€ [Background] @librarian: Research JWT best practices
  â”‚   â””â”€ Delivers report at 10min â†’ User can review early!
  â”‚
  â”œâ”€ [Background] @oracle: Design new architecture
  â”‚   â””â”€ Delivers design at 15min â†’ User can approve/adjust!
  â”‚
  â””â”€ [Main] @OmO: Start implementing (using delivered artifacts)
      â”œâ”€ Uses research report (from @librarian)
      â”œâ”€ Follows architecture (from @oracle)
      â””â”€ Implements incrementally with tests

  Total: 75 minutes, user gets updates at 10min, 15min, 30min, 60min, 75min
  User experience: Much better! Can course-correct early.

  ---
  ğŸš€ Performance Characteristics

  Resource Usage

  Sequential Model:
    CPU: 20-30% average (lots of idle time)
    Memory: ~500MB (single agent)
    Network: Bursty (one API call at a time)
    Latency: High (serial API calls)

  Parallel Model (Oh My OpenCode):
    CPU: 60-80% average (actively working)
    Memory: ~2GB (3-4 agents running)
    Network: Steady (multiple concurrent API calls)
    Latency: Lower (parallel API calls)

  Efficiency Gain: 2-4x depending on task parallelizability

  Token Consumption

  // Intelligent context sharing reduces total tokens

  Sequential (wasteful):
  Agent1: [Full Context] + Task1 = 10k tokens
  Agent2: [Full Context] + Task2 = 10k tokens
  Agent3: [Full Context] + Task3 = 10k tokens
  Total: 30k tokens

  Parallel (Oh My OpenCode):
  Shared Context: 8k tokens (loaded once)
  Agent1: [Shared] + Task1 = 10k tokens
  Agent2: [Shared] + Task2 = 10k tokens
  Agent3: [Shared] + Task3 = 10k tokens
  Total: 28k tokens + better coordination

  Savings: 10-15% tokens + much faster execution

  ---
  ğŸ“ Káº¿t luáº­n

  CÆ¡ cháº¿ Background Agents cá»§a Oh My OpenCode hoáº¡t Ä‘á»™ng nhÆ° má»™t dev team thá»±c sá»±:

  1. OmO Orchestrator = Tech Lead
    - PhÃ¢n tÃ­ch requirements
    - Chia tasks
    - Assign Ä‘Ãºng ngÆ°á»i
    - Monitor progress
    - Integrate results
  2. Specialized Agents = Team Members
    - Má»—i agent cÃ³ expertise riÃªng
    - LÃ m viá»‡c Ä‘á»™c láº­p nhÆ°ng coordinated
    - Communicate qua shared context
    - Deliver incrementally
  3. Background Task System = Async Workflow
    - Non-blocking execution
    - Parallel processing
    - Event-driven notifications
    - Graceful error handling

  Káº¿t quáº£:
  - âš¡ 2-4x faster nhá» parallel execution
  - ğŸ¯ Better quality nhá» specialized agents
  - ğŸ’° Token efficient nhá» smart context sharing
  - ğŸ˜Š Better UX nhá» incremental delivery

  ÄÃ¢y chÃ­nh lÃ  tÆ°Æ¡ng lai cá»§a AI-assisted development! ğŸš€